{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "import itertools\n",
    "import numpy as np\n",
    "from numpy import array, arange, abs as np_abs\n",
    "from scipy import signal\n",
    "from numpy.fft import rfft, rfftfreq\n",
    "import math\n",
    "from sklearn.cluster import KMeans\n",
    "import glob\n",
    "from sklearn import preprocessing\n",
    "from scipy import interpolate\n",
    "import scipy\n",
    "from sklearn.cluster import SpectralClustering\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def signalnoiseratio(x,y):    \n",
    "    \n",
    "    signalPow = math.sqrt(sum(x*np.conjugate(x)))\n",
    "    noisePow = math.sqrt(sum(y*np.conjugate(y)))\n",
    "    snr = 10 * np.log10(signalPow / noisePow)\n",
    "    \n",
    "    return snr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename_ecg = glob.glob('ЭКГ/*.dat')\n",
    "filename_class = glob.glob('Верификация/*cif.arr')\n",
    "filename_marks = glob.glob('Границы/*.Marks')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def for_open_files(filename_ecg, filename_class, filename_marks, i, error):    \n",
    "    \n",
    "    f = open(filename_ecg[i], \"r\")\n",
    "    Signal = np.fromfile(f, dtype=np.uint16)\n",
    "    Signal.resize(int(len(Signal)/3),3)\n",
    "    Class = np.genfromtxt (filename_class[i],delimiter='')\n",
    "    Marks = np.genfromtxt (filename_marks[i],delimiter='')\n",
    "    if error:\n",
    "        Marks = len_qrs_bias(Marks, Class)\n",
    "    else: \n",
    "        None\n",
    "    \n",
    "    return Signal, Class, Marks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def len_qrs_bias(Marks, Class):\n",
    "    \n",
    "    \n",
    "    # t - коэффициент стьюдента\n",
    "    L = len(Marks[:,1]-Marks[:,0])\n",
    "    M = np.mean(Marks[:,1]-Marks[:,0])\n",
    "    S = np.std(Marks[:,1]-Marks[:,0])\n",
    "    new_min = M-3*S\n",
    "    new_max = M+3*S\n",
    "    len_new_marks = np.random.randint(new_min, new_max, size=len(Marks))\n",
    "    bias = (L - len_new_marks)/2\n",
    "    bias = np.array([int(i) for i in bias])\n",
    "    Marks_new = np.copy(Marks)\n",
    "        \n",
    "    Marks_new[:,0] = Marks_new[:,0] - bias\n",
    "    Marks_new[:,1] = Marks_new[:,1] + bias\n",
    "    \n",
    "    for i in range(len(Marks_new)):\n",
    "        if Marks_new[i,1] < Class[i,2]:\n",
    "            Marks_new[i,1] = Marks_new[i,1] + 2*bias[i]\n",
    "        if Marks_new[i,0] > Class[i,2]:\n",
    "            Marks_new[i,0] = Marks_new[i,0] - 2*bias[i]\n",
    "    \n",
    "    # чекнуть на пидора\n",
    "    if Marks_new[0,0] <= 6:\n",
    "        Marks_new[0,0] = Marks[0,1]\n",
    "    if Marks_new[-1,1] >= 15000:\n",
    "        Marks_new[-1,1] = Marks[-1,1]\n",
    "    if Marks_new[0,0] > Class[0,2]:\n",
    "        Marks_new[0,0] = Marks[0,1]\n",
    "    if Marks_new[-1,1] < Class[-1,2]:\n",
    "        Marks_new[-1,1] = Marks[-1,1]\n",
    "\n",
    "    return Marks_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def for_noisy_signal(Signal, ratio):\n",
    "    \n",
    "    # функция для зашумления исходного сигнала\n",
    "    if ratio == 0:\n",
    "        signal_after_noisy_1 = Signal[:,0]\n",
    "        signal_after_noisy_2 = Signal[:,1]\n",
    "        signal_after_noisy_3 = Signal[:,2]\n",
    "        signal_after_noisy = np.column_stack((signal_after_noisy_1, signal_after_noisy_2, signal_after_noisy_3))\n",
    "    else:\n",
    "        signal_after_noisy_1 = noisy(Signal[:,0],ratio)[0]+Signal[:,0]\n",
    "        signal_after_noisy_2 = noisy(Signal[:,1],ratio)[0]+Signal[:,1]\n",
    "        signal_after_noisy_3 = noisy(Signal[:,2],ratio)[0]+Signal[:,2]\n",
    "        signal_after_noisy = np.column_stack((signal_after_noisy_1, signal_after_noisy_2, signal_after_noisy_3))\n",
    "    \n",
    "    return signal_after_noisy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# создаем шум\n",
    "def noisy(x,ratio):\n",
    "\n",
    "    k = 1\n",
    "    y = (np.random.normal(0, 1, len(x))) * k\n",
    "    nyq = 0.5 * 250\n",
    "    low = 5 / nyq\n",
    "    high = 35 / nyq\n",
    "    b, a = signal.butter(2, [low, high], btype='band')\n",
    "    y = signal.filtfilt(b, a, y)\n",
    "    snr = signalnoiseratio(x,y)\n",
    "    while snr > ratio: \n",
    "        y = (np.random.normal(0, 1, len(x))) * k\n",
    "        y = signal.filtfilt(b, a, y)\n",
    "        snr = signalnoiseratio(x,y)\n",
    "        k += 1\n",
    "        \n",
    "        #print(snr)\n",
    "\n",
    "    return y, snr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def signalnoiseratio(x,y):    \n",
    "    \n",
    "    signalPow = math.sqrt(sum(x*np.conjugate(x)))\n",
    "    noisePow = math.sqrt(sum(y*np.conjugate(y)))\n",
    "    snr = 10 * np.log10(signalPow / noisePow)\n",
    "    \n",
    "    return snr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(Signal):\n",
    "    \n",
    "    # Функция для предварительной обработки сигнала (фильтрация)\n",
    "    \n",
    "    nyq = 0.5 * 250\n",
    "    low = 5 / nyq\n",
    "    high = 20 / nyq\n",
    "    b, a = signal.butter(2, [low, high], btype='band')    \n",
    "    signal_after_processing_1 = signal.filtfilt(b, a, Signal[:,0])\n",
    "    signal_after_processing_2 = signal.filtfilt(b, a, Signal[:,1])\n",
    "    signal_after_processing_3 = signal.filtfilt(b, a, Signal[:,2])\n",
    "    signal_after_processing = np.column_stack((signal_after_processing_1, signal_after_processing_2, signal_after_processing_3))\n",
    "    \n",
    "    return signal_after_processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def informative_features(signal_after_processing, Marks, Class, pca, features):\n",
    "    \n",
    "    if len(features) == 1:\n",
    "        pca = False\n",
    "    \n",
    "    Fs = 250\n",
    "    inf_features_1 = []\n",
    "    inf_features_2 = []\n",
    "    inf_features_3 = []\n",
    "    inf_features_4 = []\n",
    "    for i in range(len(Marks)):\n",
    "        # выделение QRS-комплекса\n",
    "        QRS_complexes = signal_after_processing[int(Marks[i,0]):int(Marks[i,1])]\n",
    "        for l in range(3):\n",
    "            inf_features_one_lead = []\n",
    "            QRS = QRS_complexes[:,l]\n",
    "            # создание изолинии\n",
    "            QRS_end = len(QRS)-1\n",
    "            k = ((QRS[0] - QRS[QRS_end])/(1-len(QRS)))\n",
    "            b = (QRS[0] - ((QRS[0]-(QRS[QRS_end]))/(1-len(QRS))*1))\n",
    "            isoline = [(k*i + b) for i in range(len(QRS))]\n",
    "            # для частотных признаков (фурьешечка)\n",
    "            QRS_spectrum = np_abs(rfft(QRS, n=None, axis=-1))\n",
    "            F = rfftfreq(len(QRS), d=1/Fs) \n",
    "            # тангенс угла наклона (скорость нарастания сигнала)\n",
    "            if 1 in features:\n",
    "                QRS_square = QRS*QRS \n",
    "                inf_features_one_lead.append(np.ediff1d(QRS_square)[int(Class[i,2]-Marks[i,0]-5)]) #1\n",
    "            if 2 in features:\n",
    "            # площадь QRS-комплекса \n",
    "                inf_features_one_lead.append(sum(abs(QRS-isoline))) #2\n",
    "            # пик в частотном спектре\n",
    "            if 3 in features:    \n",
    "                inf_features_one_lead.append(F[int(np.where(QRS_spectrum == max(QRS_spectrum[(F > 5) & (F < 35)]))[0])]) #3\n",
    "            # мощность QRS-комплекса в заданном частотном диапазоне\n",
    "            if 4 in features:\n",
    "                inf_features_one_lead.append(sum(QRS_spectrum[(F > 5) & (F < 35)])) #4\n",
    "            # размах QRS-комплекса\n",
    "            if 5 in features:   \n",
    "                inf_features_one_lead.append(max(QRS)-min(QRS)) #5\n",
    "            \n",
    "            if l == 0:\n",
    "                inf_features_1.append(inf_features_one_lead)\n",
    "            elif l == 1:\n",
    "                inf_features_2.append(inf_features_one_lead)\n",
    "            elif l == 2:\n",
    "                inf_features_3.append(inf_features_one_lead)\n",
    "    \n",
    "    if 6 in features:\n",
    "        # длительность QRS-комплекса\n",
    "        len_qrs = preprocessing.scale(Marks[:,1]-Marks[:,0]) #6\n",
    "        inf_features_4 = len_qrs\n",
    "    if 7 in features:\n",
    "        RR_ratio = ratio_rr(Class) #отношения RR \n",
    "        try:\n",
    "            inf_features_4 = np.column_stack((inf_features_4, RR_ratio))\n",
    "        except:\n",
    "            inf_features_4 = RR_ratio\n",
    "    if pca:\n",
    "        num_k = 2 # количество компонент\n",
    "        pca_inf_features_1 = PCA(n_components=num_k).fit_transform(preprocessing.scale(inf_features_1))\n",
    "        pca_inf_features_2 = PCA(n_components=num_k).fit_transform(preprocessing.scale(inf_features_2))\n",
    "        pca_inf_features_3 = PCA(n_components=num_k).fit_transform(preprocessing.scale(inf_features_3))\n",
    "        try:\n",
    "            inf_features = np.column_stack((pca_inf_features_1,pca_inf_features_2,pca_inf_features_3, inf_features_4))  \n",
    "        except:\n",
    "            inf_features = np.column_stack((pca_inf_features_1,pca_inf_features_2,pca_inf_features_3))  \n",
    "    else:\n",
    "        try:\n",
    "            inf_features = np.column_stack((inf_features_1,inf_features_2,inf_features_3, inf_features_4))  \n",
    "        except:\n",
    "            inf_features = np.column_stack((inf_features_1,inf_features_2,inf_features_3))\n",
    "\n",
    "    return inf_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def for_cluster_number_elbow(X):\n",
    "    # переписать мб\n",
    "    inertia = []\n",
    "    for k in range(1, 10):\n",
    "        kmeans = KMeans(n_clusters=k, random_state=1).fit(X)\n",
    "        inertia.append(np.sqrt(kmeans.inertia_))\n",
    "    \n",
    "    clusters = []\n",
    "    for i in range(len(inertia)-1):\n",
    "        clusters.append(((inertia[i]-inertia[i+1])/inertia[i])*100)\n",
    "    \n",
    "    #find_k = [((clusters[i]-clusters[i+1])/clusters[i])*100 for i in range(len(clusters)-1)]\n",
    "    #k = int(np.where(find_k == max(find_k))[0]+1)\n",
    "\n",
    "    k = 1\n",
    "    for i in range(len(clusters)):\n",
    "        if ((clusters[i]-clusters[i+1])/clusters[i])*100 > 50:\n",
    "            k += 1\n",
    "        else:\n",
    "            break\n",
    "    \n",
    "    return k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def for_cluster_number_silhouette(X):\n",
    "\n",
    "    # переписать мб\n",
    "    k = []\n",
    "    for n_cluster in range(2, 11):\n",
    "\n",
    "        kmeans = KMeans(n_clusters=n_cluster).fit(X)\n",
    "        label = kmeans.labels_\n",
    "        sil_coeff = silhouette_score(X, label, metric='euclidean') # мб на тест выбора метрики\n",
    "        k.append(sil_coeff)\n",
    "    k = int(np.where(k == max(k))[0] + 2)\n",
    "    \n",
    "    return k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def for_efficiency(Y,y_pred,k):\n",
    "\n",
    "    # попробовать переписать через словари\n",
    "    array_k = [i for i in range(k)]\n",
    "    array_clusters = np.array([i+1 for i in range(k)])\n",
    "    arrays = list(itertools.permutations(array_clusters))\n",
    "    eff = []\n",
    "    P_array = []\n",
    "    for il in range(len(arrays)):\n",
    "        z = np.zeros((k,len(y_pred)))\n",
    "        array = arrays[il]\n",
    "        for i in range(len(y_pred)):\n",
    "            for l in range(k):\n",
    "                if y_pred[i] == array_k[l]:\n",
    "                    z[l,i] = 1\n",
    "        array_test = np.dot(array,z)\n",
    "        non_error = 0\n",
    "        for i in range(len(array_test)):\n",
    "            if Y[i] == array_test[i]:\n",
    "                non_error += 1\n",
    "        \n",
    "        P_array.append(non_error)\n",
    "        eff.append((non_error/len(array_test))*100)\n",
    "        \n",
    "    final_eff = max(eff)\n",
    "    ind = eff.index(max(eff))\n",
    "    final_result = np.dot(arrays[ind],z)\n",
    "        \n",
    "    acc = P_array[ind]/len(Y) * 100    \n",
    "    \n",
    "        \n",
    "    return final_eff, acc, final_result, P_array[ind]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ratio_rr(Class):\n",
    "\n",
    "    RR_ratio = []\n",
    "    RR = []\n",
    "    RR.append(Class[1,2] - Class[0,2])\n",
    "    for i in range(len(Class[:,2])-1):\n",
    "        RR.append(Class[i+1,2] - Class[i,2])\n",
    "    RR.append(Class[-1,2] - Class[-2,2]) \n",
    "    for i in range(len(RR)-1):\n",
    "        RR_ratio.append(RR[i]/RR[i+1])\n",
    "    RR_ratio = preprocessing.scale(RR_ratio)\n",
    "    #RR = preprocessing.scale(RR_ratio[1:-2]) \n",
    "    return RR_ratio#, RR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "column = ['features', 'pca', 'n_clust', 'method_clust', 'level_noise', 'error_duration','P', 'N', 'ACC', 'error_sg']\n",
    "condition = pd.DataFrame(columns = column)\n",
    "pre_condition = pd.DataFrame(columns = column)\n",
    "final_condition = pd.DataFrame(columns = column)\n",
    "[i for i in range(1,8)]\n",
    "features = []\n",
    "inf_f = [i for i in range(1,8)]\n",
    "for i in range(1,8):\n",
    "    features_for_append = list(itertools.combinations(inf_f, i))\n",
    "    for l in range(len(features_for_append)):\n",
    "        features.append(list(features_for_append[l]))\n",
    "pca = [True, False]\n",
    "n_clust = ['elbow','silhouette']\n",
    "method_clust = ['KM', 'SC', 'AC']\n",
    "level_noise = ['0','5','10']\n",
    "error_duration = [False, True]\n",
    "pre_condition['features'] = features\n",
    "condition = condition.append(pre_condition)\n",
    "array = [pca, n_clust, method_clust, level_noise, error_duration]\n",
    "array_name = column[1:]\n",
    "for l in range(len(array)):\n",
    "    arr = array[l]\n",
    "    condition = pre_condition\n",
    "    for i in range(len(arr)):\n",
    "        pre_condition[array_name[l]] = arr[i]\n",
    "        condition = condition.append(pre_condition)\n",
    "        #final_condition = final_condition.reset_index(drop=True)\n",
    "        #final_condition = final_condition.append(condition)\n",
    "    if i == len(arr)-1:\n",
    "        pre_condition = condition\n",
    "        #print(array_name[l])\n",
    "condition = condition.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "0 rows\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "1 rows\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "ЭКГ\\009.dat 8\n",
      "ЭКГ\\010.dat 9\n",
      "10\n",
      "11\n",
      "ЭКГ\\013.dat 12\n",
      "13\n",
      "14\n",
      "ЭКГ\\016.dat 15\n",
      "ЭКГ\\017.dat 16\n",
      "ЭКГ\\018.dat 17\n",
      "ЭКГ\\019.dat 18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n"
     ]
    }
   ],
   "source": [
    "for l in range(len(condition)):\n",
    "    try:\n",
    "        features = condition.features[l]\n",
    "        pca = condition.pca[l]\n",
    "        n_clust = condition.n_clust[l]\n",
    "        method_clust = condition.method_clust[l]\n",
    "        error = condition.error_duration[l]\n",
    "        ratio = int(condition.level_noise[l])\n",
    "\n",
    "        accuracy = []\n",
    "        P = []\n",
    "        N = []\n",
    "        error_sg = 0\n",
    "        for i in range(len(filename_ecg)):\n",
    "            try:\n",
    "                Signal, Class, Marks = for_open_files(filename_ecg, filename_class, filename_marks, i, error)\n",
    "                signal_after_noisy = for_noisy_signal(Signal, ratio)\n",
    "                signal_after_processing = preprocess(signal_after_noisy)\n",
    "\n",
    "                inf_features = informative_features(signal_after_processing, Marks, Class, pca, features)\n",
    "                #k = for_cluster_number_elbow(inf_features)\n",
    "                k = for_cluster_number_silhouette(inf_features)\n",
    "                y_pred = AgglomerativeClustering(n_clusters=k).fit_predict(inf_features)\n",
    "                accuracy.append(for_efficiency(Class[:,3],y_pred,k)[1])\n",
    "                P.append(for_efficiency(Class[:,3],y_pred,k)[3])\n",
    "                N.append(len(Class[:,3]))\n",
    "                print(i)\n",
    "            except:\n",
    "        #acc = for_efficiency(marks_qrs,y_pred,k)[1]\n",
    "                print(filename_ecg[i],i)\n",
    "                error_sg += 1\n",
    "        condition.P[l] = sum(P)\n",
    "        condition.N[l] = sum(N)\n",
    "        condition.ACC[l] = round((sum(P)/sum(N))*100,2)\n",
    "        condition.error_sg[l] = error_sg\n",
    "        print(l,'rows')\n",
    "    except:\n",
    "        condition.error_sg[l] = -1\n",
    "        print(l, 'rows error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#признаки\n",
    "'''\n",
    "\n",
    "скорость нарастания - 1\n",
    "площадь QRS-комплекса - 2\n",
    "мощность - 3\n",
    "частотак пика в частотном диапазоне - 4\n",
    "размах - 5\n",
    "длительность - 6\n",
    "отношение RR-интервалов - 7\n",
    "\n",
    "'''\n",
    "#pca\n",
    "'''\n",
    "1 - True\n",
    "2 - False\n",
    "'''\n",
    "\n",
    "# метод оптимального определения кластеров\n",
    "'''\n",
    "1 - elbow\n",
    "2 - silhoulette\n",
    "'''\n",
    "\n",
    "# метод кластеризации\n",
    "\n",
    "'''\n",
    "1 - k-means\n",
    "2 - AgglomerativeClustering\n",
    "3 - SpectralClustering\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "condition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "condition.to_excel('condition_results.xlsx',encoding='utf-8')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
